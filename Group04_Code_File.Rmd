---
title: "MIS-341 Employee Absenteesim Course Project"
author: "Group4_Section2"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    theme: readable
---

### Notes & Remarks

This r markdown project is the work of _**group 04**_ students undertaking the course __*MIS-341 : Introduction to Data Analytics*__ in **King Fahad University of Petroleum and Minerals** within KFUPM Business school department

-   Kindly press ***`Ctrl + Shift + O`*** to quickly browse through the code
-   All the codes are commented, to undo this effect: kindly select the codes in the chunks and press ***`Ctrl + Shift + C`***
-   This project is covered in a highly detailed manner, kindly visit our github repository to get the full in-depth resources of the project [Github](https://github.com/mjaali/R-Squad), it includes the `README` file that has a wider point of view coverage of the case

# Setting the resources

In this first segment, we will cover the essential tasks to do prior to any analysis. we will prepare the R studio IDE with all the required resources, and organize them in a clean manner. These duties include the following :

-   Downloading packages used for the project

The packages we will use will be retrieved from the official CRAN repository, they are basically packages designed and created by the community in order to simplify rather complicated codes into clear functions

-   Loading packages

in R studio, packages have to be installed then loaded into the environment. Therefore, we specified a chunk code for the purpose of loading the packages

-   Setting the Directory

R studio has a built in function of simplifying this task when creating an R project. But, since this project was shared on the cloud via github, we will reserve chunk of code that will set the directory per member.

-   Importing the Data set

The final step of R preparation is to import in the data for analysis. We will use clear names throughout our code to make it easier for a reviewer to investigate our analysis and follow along the coding process.

------------------------------------------------------------------------

## Libraries and Packages

```{r}
#'[ FIRST | we are going to creat a code that will install all codes required for us to do our analysis
# install.packages("tidyverse") # one of the best all-round packages for data processing
# install.packages("writexl")   # a package for reading/importing excel files into R
# install.packages("readxl")    # a package for writing/exporting R files into excel
# install.packages("scales")    # a package used to scale vectors to percentages
# install.packages("psych")     # an analysis package used for regression related statistics
# 
# #' packages installed by MQ
# install.packages("descr")
#'[ SECOND | we load all the packages into R 
library(tidyverse); library(writexl); library(readxl); library(scales); library(psych); library(desc)
```

## Directory & Import

```{r}

# Abdulrahman:

#'[ Setting the Directory
#setwd( dir = "D:/4. MIS-341/1. Course Work/00. Group Project/MIS341-02_Group 4")

#'[ Loading the File
#AbsEmployees <- read_excel("../MIS341-02_Group 4/1. input/AbsEmployees.xlsx", sheet = 1)

# Mohammed Alquraini:

#'[ Setting the Directory
# setwd( dir = "C:\\Users\\Lenovo\\Documents\\MIS431- Project\\")
#'[ Loading the File
AbsEmployees <- read_excel("./1. input/AbsEmployees.xlsx", sheet = 1)



####
# # Loading file - github fetch version
# setwd( dir = "/Users/mjaali/webapps/R-Squad/Assets/");
# AbsEmployees <- read_excel("MJ Version - AbsEmployees.xlsx", sheet = 1);
# AbsEmployees <- read_excel("Abdulrahman Version - AbsEmployees.xlsx", sheet = 1);
#duplicating the data set to re-code if necessary
emp  <- AbsEmployees
empR <- emp
#'* NOTE *
#'[ emp  : will house the data ready for analysis ( Whenever I want to go back to my original data before any adjustments, I will use AbsEmployees )
#'[ empR : will house the data archived from emp  (I never delete data, I always archive it in case I need to go back to it for the case of mistakes)
```

------------------------------------------------------------------------

# Data Pre-processing

## Data Exploration

After browsing through the data and understanding its structure, we defined some cases that need to be covered before proceeding with the analysis. Instead of deleting the suspected entries, we will create a second data frame that will house the data rejected from the analysis. Therefore, we will import the `original data set as AbsEmployees`, and then re-assign them into a data analysis set and a rejected set :

> ***emp*** : Is the name of the data analysis set that will contain the data set ready-for-analysis ***empR*** : Is the data set rejected from analysis, and it will include the following : - Ambiguous store location entries - Duplicated entries - Incorrect Age Entries

## Data Cleaning

### Extracting the data

We have observed that some data entries (employees), have ages below 18, and above 65. Legal age for working in Canada is 18 on average. Through further discussion with our manager, we have dictated that employees with ages out of these bounds will be removed from analysis.

Furthermore, some of the entries based on their store location are inconsistent. For example, A store location in a rural area will only have a single cashier. This is clearly the issue of a wrong entry of some scale in the data base. Which has also been extracted out of our analysis

The final case observed are of duplicated entries. It is uncommon to have multiple employees across different store locations to share the same first & last name, job title and so on. But it is outside the realms of reality to have multiple employees share many indicative features in the data base. Our decision was to also exclude those entries outside of our analysis, to keep our analysis as authentic as possible.

**Note :** `empR` data set will have a column on the right-most specifying why the entry was rejected from analysis. Kindly refer to it in-case of amendments.

```{r}
#'[ Extracting rejected data to empR data set
# creating new columns that will help with the analysis (will be removed later form the environments and data frame )
empR$dup <- data.frame(paste(empR$Surname, empR$GivenName, empR$Gender, empR$JobTitle, empR$DepartmentName, empR$StoreLocation ))
#'[ Employee Age cleaning ]
# extracting age restrictions
empR_age <- subset(empR, empR$Age < 18 | empR$Age > 65 | empR$Age - empR$LengthService < 18 )
# providing a columns with explanation to why the row was removed from the analysis
empR_age$drop <-  case_when( empR_age$Age < 18 ~ "Under Age",
                             empR_age$Age > 65 ~ "Over Age",
                             empR_age$Age - empR_age$LengthService < 18 ~ "Under Age")
#'[ Archiving duplicated Employee Entries ]
# extracting duplicated entries
empR_dupli <- empR[duplicated(empR$dup), ]
# providing a column with explanation to why the row was removed from the analysis
empR_dupli$drop <- paste("duplicated entry")
# merging archived data
empR <- rbind(empR_age, empR_dupli)
# deleting extra columns and removing variables from environment
empR <- subset(empR, select = -c(dup))
rm(empR_age, empR_dupli)
```

### Cleaning the Ready-for-Analysis Data

```{r}
#'[ removing incorrect entries from the data set, and preparing it for analysis
# creating new columns that will help with the analysis (will be removed later form the environments and data frame )
emp$dup <- data.frame(paste(emp$Surname, emp$GivenName, emp$Gender, emp$JobTitle, emp$DepartmentName, emp$StoreLocation ))
#'[ Deleting Under/over age Employee Entries ]
emp <- emp %>%
  filter(, Age > 18) %>%
  filter(, Age < 65) %>%
  filter(, Age - LengthService > 18)
#'[ Deleting duplicated Employee Entries ]
# deleting duplicate entries
emp <- emp[!duplicated(emp$dup), ]
# deleting excess columns
emp <- subset(emp, select = -c(dup))



```

## Data Wrangling

In this part, we are concerned with any manipulation required in order to improve the statistical accuracy and quality of our study. Therefore, after a keen study of the data and the case at hand, we have introduced the following variables :

-   **AbsHoursPerTenure** : This variable will be our dependent variable, the feature that is already existent in the data only accounts for the absent hours, regardless of the years of tenure. Since it is not statistically feasible to compare the absence of multiple employees with different tenures, it was decided to make a new variable that will take the proportional absence hours per year of service.

-   **EmployeeType** : This new variable will identify which type of employee we are studying, are they a working employee as a cashier or a back-end employee as a finance staff, this will help us identify which employee we can't afford to go absent

-   **EmployeeSector** : This variable will help us identify absenteeism based on the sector the employee works in, it answers the question of "Are finance employees more likely to go absent in comparison to HR employees?".

```{r}
# (1) creating a proportional Absence hours per year in the company
emp$'AbsHrsPerTenure'   <- (emp$AbsentHours/emp$LengthService)



# (3) adding a variable identifying the type of employee
emp$EmployeeType <- if_else( emp$JobTitle %in% c("Cashier", "Produce Clerk", "Shelf Stocker", "Dairy Person", "Meat Cutter", "Baker"), "Working Employee",
                             if_else(emp$JobTitle %in% c("Store Manager", "Customer Service Manager", "Produce Manager", "Processed Foods Manager", "Dairy Manager", "Meats Manager", "Bakery Manager"), "Work-Manager Employee",
                                     if_else(emp$JobTitle %in% c("Auditor", "Investment Analyst", "Accounting Clerk", "Accounts Payable Clerk", "Accounts Receiveable Clerk", "Trainer", "Compensation Analyst", "Labor Relations Analyst", "Recruiter", "Benefits Admin", "HRIS Analyst", "Systems Analyst", "Corporate Lawyer"), "Staff Employee",
                                             if_else(emp$JobTitle %in% c("Director, Audit", "Director, Investments", "Director, Accounting", "Director, Accounts Payable", "Director, Accounts Receivable", "Director, Training", "Director, Compensation", "Director, Labor Relations", "Director, Recruitment", "Director, Employee Records", "Director, HR Technology"), "Staff-Manager Employee",
                                                     if_else(emp$JobTitle %in% c("VP Finance", "Exec Assistant, Finance", "VP Human Resources", "Exec Assistant, Human Resources", "Exec Assistant, Human Resources", "VP Stores", "Exec Assistant, VP Stores", "CIO", "CEO", "Legal Counsel", "Exec Assistant, Legal Counsel", "CHief Information Officer" ), "Executive Employee",
                                                             emp$JobTitle)))))



# (3) adding a unit categorizing the division of the employee
emp$EmployeeSector <- if_else(emp$JobTitle %in% c("Cashier", "Produce Clerk", "Shelf Stocker", "Dairy Person", "Meat Cutter", "Baker", "Store Manager", "Customer Service Manager", "Produce Manager", "Processed Foods Manager", "Dairy Manager", "Meats Manager", "Bakery Manager"), "Stores Sector",
                      if_else(emp$JobTitle %in% c("Trainer", "Compensation Analyst", "Labor Relations Analyst", "Recruiter", "Benefits Admin", "HRIS Analyst", "Systems Analyst", "Corporate Lawyer", "Director, Training", "Director, Compensation", "Director, Labor Relations", "Director, Recruitment", "Director, Employee Records", "Director, HR Technology"), "Human Resources Sector",
                              if_else(emp$JobTitle %in% c("Auditor", "Investment Analyst", "Accounting Clerk", "Accounts Payable Clerk", "Accounts Receiveable Clerk", "Director, Audit", "Director, Investments", "Director, Accounting", "Director, Accounts Payable", "Director, Accounts Receivable"), "Finance Sector",
                                      "Chief/BoD")))




```

## Data Classification

after the addition of the variables that we will use for prediction. We will remove unnecessary variables from the statistical analysis, such variables are within the realms of **EmployeeNumber**, **Surname**, **GivenName**... etc. Any variable that will not affect the dependent variable will be removed from the data set.

Additionally, we will ensure data variables represent their correct data types. We will make sure a number variable is identified as `double` instead of `character`. We have to ensure the data types are assignet correctly in order to create dummy variables and use our predictive models ensuring our results are valid.

```{r}
# removing excess variables and re-ordering the data
emp <- emp %>% 
  select(, "EmployeeNumber", "EmployeeSector", "EmployeeType", "Gender", "JobTitle", "DepartmentName", "Division", "BusinessUnit", "StoreLocation", "Age", "LengthService", "AbsentHours", "AbsHrsPerTenure" )

# assigning the correct data types
emp$EmployeeSector <- as.factor(emp$EmployeeSector)
emp$EmployeeType <- as.factor(emp$EmployeeType)
emp$Gender <- as.factor(emp$Gender)
emp$DepartmentName <- as.factor(emp$DepartmentName)
emp$Division <- as.factor(emp$Division)
emp$BusinessUnit <- as.factor(emp$BusinessUnit)

# the rest of the variables are correctly assigned (as intended)



```

with the above codes in place, we have prepared our data for analysis. we explored the data for potential incorrect entries, we examined and removed any observation to another data set `empR`. additionally, we cleaned our main data set, added new variables to be studied, assigned the correct data types and ensured the data will function properly using r language statistical predictive models. `emp` is ready-for-analysis, and we will proceed to the next part of the report were we clarify how we will conduct our analysis to find the most influencial factors relating to employee absenteeism.

------------------------------------------------------------------------

# Analysis

After we cleaned the data set, we commenced to the next segment in our project, which is the analysis of the data. the goal of the project is to identify factors that are most effective to absenteeism in the company, highlight them and offer our business recommendations on how to reduce them. Firstly, to reach that conclusion, we will do a descriptive analysis to understand what is currently happening. Secondly, we will use our findings from the descriptive analysis and conduct our predictive analysis to objectively project what will most likely to happen if we were to go through our recommendations. 



## Descriptive Statistics

In this segment of the project we will attempt to explore the data, and find correlations in our variables given. From this analysis, we will identify phenomenons and patterns that will justify the absenteeism causes within the company.




### Absenteeism and Length service

We wanted to test link between the connection between how long an employee has served the company and the absenteesim rate they have. The logic behind this is the fact that if someone served more in the company, are they more likely or less likely to go absent?

```{r}


#'* a graph that shows the link between Length Service & AbsHrsPerTenure *

#'[ A graph shows the results regardless of the business unit
emp %>%
  ggplot() +
  aes(x=LengthService, y=AbsHrsPerTenure) +             # naming the x,y axis
  geom_point(colour = "violet") +                       # Coloring the dots in the graph
  coord_cartesian(xlim = c(0, 40), ylim = c(0, 100)) +  # setting limits to x,y axis (if we keep the outliers, the graph will be so big that we can't see the relationship)
  theme_minimal()                                       # the theme/style of the plot


#'[ A graph shows the results for Stores business unit
emp %>%
  filter(, BusinessUnit == "Stores") %>% 
  ggplot() +
  aes(x=LengthService, y=AbsHrsPerTenure) +             # naming the x,y axis
  geom_point(colour = "red") +                          # Coloring the dots in the graph
  coord_cartesian(xlim = c(0, 40), ylim = c(0, 100)) +  # setting limits to x,y axis (if we keep the outliers, the graph will be so big that we can't see the relationship)
  theme_minimal()                                       # the theme/style of the plot



#'[ A graph shows the results for Headoffice business unit
emp %>%
  filter(, BusinessUnit == "HeadOffice") %>% 
  ggplot() +
  aes(x=LengthService, y=AbsHrsPerTenure) +             # naming the x,y axis
  geom_point(colour = "blue") +                         # Coloring the dots in the graph
  coord_cartesian(xlim = c(0, 40), ylim = c(0, 100)) +  # setting limits to x,y axis (if we keep the outliers, the graph will be so big that we can't see the relationship)
  theme_minimal()                                       # the theme/style of the plot



```

>findings

we can observe from the above graphs a great that there is a link between length service and absenteeism. the **purple graph** shows the overall relationship between absent hours per tenure for `all employees`. We observed a pattern and decided to do a deep dive as per business unit, and our findings were informative. the **red graph** shows the same graph but uniquely to `stores`,  and the **blue graph** shows the relationship for `head office` employees. 

we can summize from the graphs that for stores employees, they clutter absenteeism early service years, around 0 ~ 10 years of service. Whereas head office employees distribute their absences over their years service. This information is crucial because it gave us a new point of view to observe patterns, now we are considering the absenteeism culture over the whole business unit. Addtionally, we will start to deep dive the importance of absences in Stores unit. We will do analysis on who we deem most important to not be absent. For example, if a high number of `Cashiers` go absent, customers will bottleneck on checkout, jeopardizing the in-store customer experience of the store.


### Absenteeism and Age 

The one the most logical correlations is the age of the employee and how it affects the absenteeism rate they incur. This analysis answers the questions of _"Is the employee more likely to be absent the older they are? does age affect absenteeism?"_

```{r}

#'* a graph that shows the link between Age and Absence Hours Per Tenure                                                                                                                                       *


#'[ A graph shows the results for the relationship between age & absHrsPerTenure
emp %>%
  ggplot() +
  geom_point(aes(x = Age,y = AbsHrsPerTenure), colour = "purple") + # setting the aesthetics for the points + defining xy axis
  coord_cartesian(xlim = c(15, 60), ylim = c(0, 100)) +             # limiting the xy axis
  theme_minimal()                                                   # setting the theme for the graph



#'[ A graph shows the results for the relationship between age & absHrsPerTenure
emp %>%
  ggplot() +
  geom_point(aes(x = Age,y = AbsHrsPerTenure), colour = "green") +    # setting the aesthetics for the points + defining xy axis
  coord_cartesian(xlim = c(15, 60), ylim = c(-20, 100)) +             # limiting the xy axis
  geom_smooth(aes(x = Age,y = AbsHrsPerTenure) ,method = 'lm') +      # drawing a linear model line in the graph
  theme_minimal()                                                     # setting the theme for the graph



```


> findings

the findings of these graphs will shape our decision for the report. We can observe a very interesting phenomena when plotting age and absence hours per tenure, the graph shows how the absence hours per tenure increases referring to the age. Starting approximately the age 25, absenteeism increases around 0.9 hours. With this observation we can deduce that as for now, this is the strongest correlation we were able to find thus far. We will keep this graph in mind whilst making our recommendation, as well as explore it in the point of view of its effects per job title.


## Predictive Statistics

```{r}
##################

#Firstly, We will do our correlation matrix to determine the correlation between the independent variables and our response variable, but since our data contain numeric and nonnumerical variable, we will do the correlation matrix manually.

# Note* 
#   We have selected our respond variable to be AbsentHours.

m_V1 <- model.matrix(~ AbsentHours - 1, emp)
m_V2 <- model.matrix(~ Gender - 1, emp)
m_V3 <- model.matrix(~ JobTitle - 1, emp)
m_V4 <- model.matrix(~ DepartmentName - 1, emp)
m_V5 <- model.matrix(~ StoreLocation - 1, emp)
m_V6 <- model.matrix(~ Division - 1, emp)
m_V7 <- model.matrix(~ BusinessUnit - 1, emp)
m_V8 <- model.matrix(~ Age - 1, emp)
m_V9 <- model.matrix(~ LengthService - 1, emp)
m_V10 <- model.matrix(~ EmployeeSector - 1, emp)
m_V11 <- model.matrix(~ EmployeeType - 1, emp)
m_V12 <- model.matrix(~ AbsHrsPerTenure - 1, emp)
##

# Now we will do our correlation matrix between our response variable and other variables in the dataset.

cor(m_V1, m_V2)
cor(m_V1, m_V3)
cor(m_V1, m_V4) 
cor(m_V1, m_V5)
cor(m_V1, m_V6)
cor(m_V1, m_V7) 
cor(m_V1, m_V8)
cor(m_V1, m_V9)
cor(m_V1, m_V10) 
cor(m_V1, m_V11)
cor(m_V1, m_V12)

# After computing the correlation between our response variable and other variables, we will do tests of the correlations between some variables to test our assumptions of having multicolinearity between some variables.

# First test will be between BusinessUnit and Division.

cor(m_V6, m_V7) 

# As we can see, we have a significant 100% correlation between DivisionStores and (BusinessUnitHeadOffice and BusinessUnitStores), which is indicates that the presence of the two variables in our model will result in a multicolinearity issues.
# Therefore, our optimal solution is to remove one of the two variables.

#############

# Now, we will test the correlation between JubTitle and DepartmentName.

cor(m_V3, m_V4)

# Based on the obtained results, we can conclude that the presence of these two variables will create a problem of multicolinearity, due to the high correlation (more than95%) between some of the observations.

# Therefore, our optimal solution is to remove one of the two variables.


#############
# For the other variables, there is  no need for testing the correlation between them, due to that it seems that there is no significant correlation between them, but if a high correlation was percent, R will find it and solve the problem.

########################

# After computing the correlation matrix, we will try to run models for each variable to determine which variable has the highest impact.

# for our individuals model we will use (emp) as our dataset.



model01 <- lm(AbsentHours ~Gender, data = emp)

summary(model01)$r.squared

# R-squared of model1 is 0.01436839

model02 <- lm(AbsentHours ~JobTitle, data = emp)

summary(model02)$r.squared

# R-squared of model02 is 0.006038185

model03 <- lm(AbsentHours ~DepartmentName, data = emp)

summary(model03)$r.squared

# R-squared of model03 is 0.003656944

model04 <- lm(AbsentHours ~StoreLocation, data = emp)

summary(model04)$r.squared

# R-squared of model04 is 0.004578336

model05 <- lm(AbsentHours ~Division, data = emp)

summary(model05)$r.squared

# R-squared of model05 is 0.001522046

model06 <- lm(AbsentHours ~BusinessUnit, data = emp)

summary(model06)$r.squared

# R-squared of model06 is 0.001057944

model07 <- lm(AbsentHours ~Age, data = emp)

summary(model07)$r.squared

# R-squared of model07 is 0.6833127

model08 <- lm(AbsentHours ~LengthService, data = emp)

summary(model08)$r.squared

# R-squared of model08 is 0.0005958677

model09 <- lm(AbsentHours ~EmployeeSector, data = emp)

summary(model09)$r.squared

# R-squared of model09 is 0.001376249

model10 <- lm(AbsentHours ~EmployeeType, data = emp)

summary(model10)$r.squared

# R-squared of model10 is 0.001526995

model11 <- lm(AbsentHours ~AbsHrsPerTenure, data = emp)

summary(model11)$r.squared

# R-squared of model11 is 0.1665376

# * From the obtained result we can see that the ] variable that has the highest impact on response variable is (Age),

##########
# Now, we will run a model with all variables.

model12 <- lm(AbsentHours ~., data = emp)

#############

# After computing the models, we will create a new dataset to implement our First model based on the variables that we saw a high impact on them.

PredData <- emp

# (PredData) refer to the data that we are going to use in our predictions and model building.


PredData = subset(PredData, select = -c(DepartmentName, Division) )

# We have deleted the listed variables to implement our first model because of the below reasons:


# DepartmentName: Because it is related to the JobTitle, therefore, if we include it in the model a multicolinearity problem will rise.

# *Note:  we can do the oppeste but we will do it this way at the moment until we find our optimal model.

# Division: Becuase it is related to the BusinessUnit, therefore, if we include it in the model a multicolinearity problem will rise.

# *Note:  we can do the oppeste but we will do it this way at the moment until we find our optimal model.


model13 <- lm(AbsentHours ~., data = PredData)
anova(model01)

# According to the results optained using this model, it shows that there is some NA values, to reduce them to minimum, we will try some advanced methods of modeling.


###################################

# Now, we will try other methods of building our final model using different approaches of building models, listed below:

# 1- Backward elemenation

# 2 - Forward Stepwise

###################################

# Backward elemination method:

BackwardData <- emp

# BackwardData represent the data that we are going to use to impelemente our model using backward elemination method.

Model14 <- lm(AbsentHours ~., data = BackwardData)

Model14 <- step(Model14, direction = "backward", trace=FALSE ) 

# As we can see, after using Backward Elemination method, the problem of NA values has been solved.

#Now, we will view the results of Backward elemination regression

Model14$anova

#Finally, we will view our model of backward elemination method.

Model14$coefficients

#####################################

# Here, we will use Forward stepwise regression method

Stipwisedata <- emp

# Stipwisedata represent the data that we are going to use to impelemente our model using Forward stepwise method.


# To impelement our forward stipwise method we should folow the folowing steps:


#Firstly, we will define our intercept-only model

intercept_only <- lm(AbsentHours~ 1, data=Stipwisedata)

#Secondly, we will define a model with all predictors

model15 <- lm(AbsentHours ~ ., data=Stipwisedata)


# Finally, we wil perform forward stepwise regression

Model16 <- step(intercept_only, direction='forward', scope=formula(model15), trace=0)

# As we explained in the model of Backward elimination, also, after impilementing Forward Stepwise regression the problem of NA values has been solved.

#Now, we will view the results of forward stepwise regression

Model16$anova

#At the end, we will view our final model of forward stepwise method.

Model16$coefficients


##################################################

# As we can see, using these two approaches (Backward elemination, Forward stepwise), we got the same results!. Therefore, our optimal model will be either Backward elemination or Forward stepwise with the coffecients showing in the ANOVA table.

rm(m_V1, m_V2, m_V3, )


# To be continued........ :)
```

------------------------------------------------------------------------


# Recommendation
The Cashier has the highest Absinteesm Culture level. In the city of Vancouver, the age `24.51` y/o and beyond is where Absenteeism hours escalate with a strong correlation for both males and females at a `slope of 0.9395x`. Since our x-intercept is `24.51`, or in other words, Cashiers below the age of 24.51 have no absinteesm hours `(0 Hrs / year)`. The avg. tenure of the Cashier is `4.58 years`. A policy to hire Cashiers of a maximum of `20 y/o` will ensure most cashiers will clear out of the company before they turn 25 and reduce overall company absenteeism significantly. However, we have to validate if these young cashiers are full-time or part-time in order to control the cost associated with high-frequancy and high-volume recruting, plus investigate the compensation increase as a result, along with the total supply of such type of workers.
